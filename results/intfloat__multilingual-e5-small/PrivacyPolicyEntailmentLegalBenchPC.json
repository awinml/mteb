{
  "dataset_revision": "12ca3b695563788fead87a982ad1a068284413f4",
  "mteb_dataset_name": "PrivacyPolicyEntailmentLegalBenchPC",
  "mteb_version": "1.7.7",
  "test": {
    "cos_sim": {
      "accuracy": 0.8623046875,
      "accuracy_threshold": 0.9008374214172363,
      "ap": 0.11117809367298936,
      "f1": 0.24065320154705624,
      "f1_threshold": 0.7616734504699707,
      "precision": 0.13685239491691104,
      "recall": 0.99644128113879
    },
    "dot": {
      "accuracy": 0.8623046875,
      "accuracy_threshold": 0.9008374214172363,
      "ap": 0.11117837265159107,
      "f1": 0.24065320154705624,
      "f1_threshold": 0.7616734504699707,
      "precision": 0.13685239491691104,
      "recall": 0.99644128113879
    },
    "euclidean": {
      "accuracy": 0.8623046875,
      "accuracy_threshold": 0.44529417157173157,
      "ap": 0.11117809367298939,
      "f1": 0.24065320154705624,
      "f1_threshold": 0.6903994083404541,
      "precision": 0.13685239491691104,
      "recall": 0.99644128113879
    },
    "evaluation_time": 143.72,
    "manhattan": {
      "accuracy": 0.8623046875,
      "accuracy_threshold": 7.062281608581543,
      "ap": 0.11676906963380135,
      "f1": 0.24156791248860526,
      "f1_threshold": 10.10442066192627,
      "precision": 0.13852587558808155,
      "recall": 0.9430604982206405
    },
    "max": {
      "accuracy": 0.8623046875,
      "ap": 0.11676906963380135,
      "f1": 0.24156791248860526
    }
  }
}