{
  "dataset_revision": "12ca3b695563788fead87a982ad1a068284413f4",
  "mteb_dataset_name": "ContractQALegalBenchPC",
  "mteb_version": "1.7.7",
  "test": {
    "cos_sim": {
      "accuracy": 0.9875,
      "accuracy_threshold": 0.8213544487953186,
      "ap": 0.9943589743589744,
      "f1": 0.9870129870129869,
      "f1_threshold": 0.8213544487953186,
      "precision": 1.0,
      "recall": 0.9743589743589743
    },
    "dot": {
      "accuracy": 0.9875,
      "accuracy_threshold": 0.8213544487953186,
      "ap": 0.9943589743589744,
      "f1": 0.9870129870129869,
      "f1_threshold": 0.8213544487953186,
      "precision": 1.0,
      "recall": 0.9743589743589743
    },
    "euclidean": {
      "accuracy": 0.9875,
      "accuracy_threshold": 0.5977367162704468,
      "ap": 0.9943589743589744,
      "f1": 0.9870129870129869,
      "f1_threshold": 0.5977367162704468,
      "precision": 1.0,
      "recall": 0.9743589743589743
    },
    "evaluation_time": 3.91,
    "manhattan": {
      "accuracy": 0.95,
      "accuracy_threshold": 9.19456672668457,
      "ap": 0.9886061820706123,
      "f1": 0.9487179487179487,
      "f1_threshold": 9.317394256591797,
      "precision": 0.9487179487179487,
      "recall": 0.9487179487179487
    },
    "max": {
      "accuracy": 0.9875,
      "ap": 0.9943589743589744,
      "f1": 0.9870129870129869
    }
  }
}